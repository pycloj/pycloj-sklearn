(ns sklearn.ensemble.gradient-boosting.BaseGradientBoosting
  "Abstract base class for Gradient Boosting. "
  (:require [libpython-clj.python
             :refer [import-module
                     get-item
                     get-attr
                     python-type
                     call-attr
                     call-attr-kw]:as py]))

(py/initialize!)
(defonce gradient-boosting (import-module "sklearn.ensemble.gradient_boosting"))

(defn BaseGradientBoosting 
  "Abstract base class for Gradient Boosting. "
  [loss learning_rate n_estimators criterion min_samples_split min_samples_leaf min_weight_fraction_leaf max_depth min_impurity_decrease min_impurity_split init subsample max_features random_state & {:keys [alpha verbose max_leaf_nodes warm_start presort validation_fraction n_iter_no_change tol]
                       :or {alpha 0.9 verbose 0 warm_start false presort "auto" validation_fraction 0.1 tol 0.0001}} ]
    (py/call-attr-kw gradient-boosting "BaseGradientBoosting" [loss learning_rate n_estimators criterion min_samples_split min_samples_leaf min_weight_fraction_leaf max_depth min_impurity_decrease min_impurity_split init subsample max_features random_state] {:alpha alpha :verbose verbose :max_leaf_nodes max_leaf_nodes :warm_start warm_start :presort presort :validation_fraction validation_fraction :n_iter_no_change n_iter_no_change :tol tol }))

(defn apply 
  "Apply trees in the ensemble to X, return leaf indices.

        .. versionadded:: 0.17

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape (n_samples, n_features)
            The input samples. Internally, its dtype will be converted to
            ``dtype=np.float32``. If a sparse matrix is provided, it will
            be converted to a sparse ``csr_matrix``.

        Returns
        -------
        X_leaves : array-like, shape (n_samples, n_estimators, n_classes)
            For each datapoint x in X and for each tree in the ensemble,
            return the index of the leaf x ends up in each estimator.
            In the case of binary classification n_classes is 1.
        "
  [ self X ]
  (py/call-attr self "apply"  self X ))

(defn feature-importances- 
  "Return the feature importances (the higher, the more important the
           feature).

        Returns
        -------
        feature_importances_ : array, shape (n_features,)
            The values of this array sum to 1, unless all trees are single node
            trees consisting of only the root node, in which case it will be an
            array of zeros.
        "
  [ self ]
    (py/call-attr self "feature_importances_"))

(defn fit 
  "Fit the gradient boosting model.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape (n_samples, n_features)
            The input samples. Internally, it will be converted to
            ``dtype=np.float32`` and if a sparse matrix is provided
            to a sparse ``csr_matrix``.

        y : array-like, shape (n_samples,)
            Target values (strings or integers in classification, real numbers
            in regression)
            For classification, labels must correspond to classes.

        sample_weight : array-like, shape (n_samples,) or None
            Sample weights. If None, then samples are equally weighted. Splits
            that would create child nodes with net zero or negative weight are
            ignored while searching for a split in each node. In the case of
            classification, splits are also ignored if they would result in any
            single class carrying a negative weight in either child node.

        monitor : callable, optional
            The monitor is called after each iteration with the current
            iteration, a reference to the estimator and the local variables of
            ``_fit_stages`` as keyword arguments ``callable(i, self,
            locals())``. If the callable returns ``True`` the fitting procedure
            is stopped. The monitor can be used for various things such as
            computing held-out estimates, early stopping, model introspect, and
            snapshoting.

        Returns
        -------
        self : object
        "
  [ self X y sample_weight monitor ]
  (py/call-attr self "fit"  self X y sample_weight monitor ))

(defn get-params 
  "Get parameters for this estimator.

        Parameters
        ----------
        deep : boolean, optional
            If True, will return the parameters for this estimator and
            contained subobjects that are estimators.

        Returns
        -------
        params : mapping of string to any
            Parameter names mapped to their values.
        "
  [self  & {:keys [deep]
                       :or {deep true}} ]
    (py/call-attr-kw self "get_params" [] {:deep deep }))

(defn set-params 
  "Set the parameters of this estimator.

        The method works on simple estimators as well as on nested objects
        (such as pipelines). The latter have parameters of the form
        ``<component>__<parameter>`` so that it's possible to update each
        component of a nested object.

        Returns
        -------
        self
        "
  [ self  ]
  (py/call-attr self "set_params"  self  ))
